{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d6002b3-20dc-43af-9ed5-eae963a6e4d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "dkoM_ePNEMk1"
   },
   "source": [
    "A0287147U Cai Xiaoqi Jessica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd4e2ebe-46a1-43d7-8c82-6bb903265248",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "nS8J96UjDzc6"
   },
   "source": [
    "### Task 1: Data Loading and Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea59c29d-b8fd-438b-8f79-0743c0bdf0ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "86Y3o9-LEVUS"
   },
   "source": [
    "#### Data Loading (10 marks)\n",
    "* Load the Bank Marketing dataset into a Spark DataFrame using PySpark.\n",
    "* Use the bank-full.csv file provided as the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20e62824-8e2f-47c5-8e0d-b2c7a851763d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "IWxliV_5D3dO",
    "outputId": "53d51bd2-9546-4352-bc16-1e37394b1be3"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
    "\n",
    "# Create a SparkSession -> creates the entry point to all Spark functionality.\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"bank_insight\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# everything is concatenated together in csv file so need to define schema\n",
    "bank_schema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"job\", StringType(), True),\n",
    "    StructField(\"marital\", StringType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"default\", StringType(), True),\n",
    "    StructField(\"balance\", IntegerType(), True),\n",
    "    StructField(\"housing\", StringType(), True),\n",
    "    StructField(\"loan\", StringType(), True),\n",
    "    StructField(\"contact\", StringType(), True),\n",
    "    StructField(\"day\", IntegerType(), True),\n",
    "    StructField(\"month\", StringType(), True),\n",
    "    StructField(\"duration\", IntegerType(), True),\n",
    "    StructField(\"campaign\", IntegerType(), True),\n",
    "    StructField(\"pdays\", IntegerType(), True),\n",
    "    StructField(\"previous\", IntegerType(), True),\n",
    "    StructField(\"poutcome\", StringType(), True),\n",
    "    StructField(\"y\", StringType(), True)  # Target variable (yes/no)\n",
    "])\n",
    "\n",
    "# Define the path to dataset.\n",
    "data_path = \"/FileStore/tables/bank_full.csv\"\n",
    "\n",
    "# use sparkession to read data -> working with dataFrames not RDDs\n",
    "df = spark.read.csv(data_path, header=True, schema=bank_schema, sep = \";\")\n",
    "\n",
    "# Write the DataFrame to a Parquet file in DBFS (overwrite mode)\n",
    "df.write.mode(\"overwrite\").parquet(\"/tmp/bank_parquet\")\n",
    "\n",
    "# Write the DataFrame to a CSV file in DBFS (overwrite mode and include header)\n",
    "df.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/tmp/bank_csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b546d679-d599-4108-b864-594419c3a4f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tmJki2NxEbk_"
   },
   "source": [
    "#### Exploration Using DataFrame API and Spark SQL (15 marks)\n",
    "* Display the schema and show a sample (5 rows) of the data using the\n",
    "DataFrame API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b44e78d3-677a-4dce-acbf-c3ff88643d3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n",
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "|age|job         |marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|y  |\n",
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "|58 |management  |married|tertiary |no     |2143   |yes    |no  |unknown|5  |may  |261     |1       |-1   |0       |unknown |no |\n",
      "|44 |technician  |single |secondary|no     |29     |yes    |no  |unknown|5  |may  |151     |1       |-1   |0       |unknown |no |\n",
      "|33 |entrepreneur|married|secondary|no     |2      |yes    |yes |unknown|5  |may  |76      |1       |-1   |0       |unknown |no |\n",
      "|47 |blue-collar |married|unknown  |no     |1506   |yes    |no  |unknown|5  |may  |92      |1       |-1   |0       |unknown |no |\n",
      "|33 |unknown     |single |unknown  |no     |1      |no     |no  |unknown|5  |may  |198     |1       |-1   |0       |unknown |no |\n",
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display schema\n",
    "df.printSchema()\n",
    "df.show(5, truncate=False)\n",
    "\n",
    "# Cache the final DataFrame to speed up any subsequent operations.\n",
    "df = df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6096b5cb-f315-49f0-b92a-80c0ad995769",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "* Write and execute at least two Spark SQL queries. For instance, use one query\n",
    "for demographic features (age, balance) and another for campaign attributes\n",
    "(campaign duration), each calculating summary statistics (count, average, min,\n",
    "max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bc5fae2-dd58-4e29-a23d-263eb513da27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "0Oe3P0CXEi2M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+-------+-------+------------------+-----------+-----------+\n",
      "|total_records|          avg_age|min_age|max_age|       avg_balance|min_balance|max_balance|\n",
      "+-------------+-----------------+-------+-------+------------------+-----------+-----------+\n",
      "|        45211|40.93621021432837|     18|     95|1362.2720576850766|      -8019|     102127|\n",
      "+-------------+-----------------+-------+-------+------------------+-----------+-----------+\n",
      "\n",
      "+-----------+-----------------+------------+------------+-----------------+------------+------------+\n",
      "|total_calls|     avg_duration|min_duration|max_duration|     avg_campaign|min_campaign|max_campaign|\n",
      "+-----------+-----------------+------------+------------+-----------------+------------+------------+\n",
      "|      45211|258.1630797814691|           0|        4918|2.763840658246887|           1|          63|\n",
      "+-----------+-----------------+------------+------------+-----------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary view so you can run SQL queries on the DataFrame.\n",
    "df.createOrReplaceTempView(\"bank_data\")\n",
    "\n",
    "# query for age and balance\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        COUNT(*) AS total_records,\n",
    "        AVG(age) AS avg_age,\n",
    "        MIN(age) AS min_age,\n",
    "        MAX(age) AS max_age,\n",
    "        AVG(balance) AS avg_balance,\n",
    "        MIN(balance) AS min_balance,\n",
    "        MAX(balance) AS max_balance\n",
    "    FROM bank_data\n",
    "\"\"\").show()\n",
    "\n",
    "# query for call duration and campaign contacts\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        COUNT(*) AS total_calls,\n",
    "        AVG(duration) AS avg_duration,\n",
    "        MIN(duration) AS min_duration,\n",
    "        MAX(duration) AS max_duration,\n",
    "        AVG(campaign) AS avg_campaign,\n",
    "        MIN(campaign) AS min_campaign,\n",
    "        MAX(campaign) AS max_campaign\n",
    "    FROM bank_data\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f8fe09a-a075-43ca-ad2a-6a8b281ff118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "* In your markdown cells, include a brief discussion on how these exploratory steps help in understanding the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bc596fd-55a5-4d31-8b29-341af5886ee1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "KdKLysKYFi20"
   },
   "source": [
    "Inspecting the schema ensures all columns have the correct data types, which prevents issues during transformations. \n",
    "Viewing the first few rows confirms that the data is properly loaded and parsed.\n",
    "\n",
    "\n",
    "The first SQL query provides insights into customer demographics.\n",
    "The average customer age is approximately **40.94 years**, with a range from **18 to 95**, indicating a broad age distribution.  \n",
    "The average account balance is around **1362.27**, ranging from **-8019 to 102127** (currency unit not specified, but likely in euros). The wide spread and presence of negative balances suggest financial diversity, from wealthy individuals to those potentially in debt. These insights help identify customer segments that may behave differently.\n",
    "\n",
    "The second SQL query focuses on marketing campaign effectiveness.\n",
    "The average call duration is **258 seconds** (~4.3 minutes), ranging from **0 to 4918** seconds. A `duration = 0` likely means no engagement, which is important for modeling.  \n",
    "The average number of contacts per client during the campaign is **2.76**, with a maximum of **63**. Extremely high contact counts may indicate over-marketing, potentially leading to customer fatigue.\n",
    "\n",
    "These exploratory insights give us a better understanding of our dataset’s structure and possible feature relevance. Features like **balance**, **age**, **duration**, and **campaign frequency** may be strong predictors of whether a customer subscribes to a term deposit, and could guide our future feature engineering.\n",
    "\n",
    "These exploratory steps highlight which features (e.g., **age**, **balance**, **duration**, **campaign**) are likely influential in predicting term deposit subscriptions. They also guide feature engineering, help assess data quality, and inform business strategies such as customer segmentation and engagement timing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16af8c2b-2465-491f-b97d-1ada803edd81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "GhIIDIC7D328"
   },
   "source": [
    "### Task 2: Feature Engineering with Window Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49230cd2-29d2-4b2e-a88a-9be611f804a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "blqNsk_BEpYy"
   },
   "source": [
    "#### Target Variable Transformation (5 marks)\n",
    "* Convert the target variable (subscription) into a binary label (1 for “yes”, 0 for “no”).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2efd0ad5-d3b4-451d-ae16-a02da212f958",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ZrRUZ8bxD6Tt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-2902284467641502>:5\u001b[0m\n",
       "\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringIndexer\n",
       "\u001b[1;32m      4\u001b[0m indexer \u001b[38;5;241m=\u001b[39m StringIndexer(inputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, outputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
       "\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m indexer\u001b[38;5;241m.\u001b[39mfit(df)\u001b[38;5;241m.\u001b[39mtransform(df)\n",
       "\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Show results to verify\u001b[39;00m\n",
       "\u001b[1;32m      8\u001b[0m df\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m10\u001b[39m)\n",
       "\n",
       "File \u001b[0;32m/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_pyspark.py:30\u001b[0m, in \u001b[0;36m_create_patch_function.<locals>.patched_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
       "\u001b[1;32m     28\u001b[0m call_succeeded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
       "\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
       "\u001b[0;32m---> 30\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m     31\u001b[0m     call_succeeded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
       "\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n",
       "\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n",
       "\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
       "\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
       "\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n",
       "\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n",
       "\u001b[1;32m    210\u001b[0m     )\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/ml/wrapper.py:383\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n",
       "\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n",
       "\u001b[0;32m--> 383\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m    384\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n",
       "\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/ml/wrapper.py:380\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n",
       "\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
       "\u001b[1;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n",
       "\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n",
       "\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n",
       "\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n",
       "\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n",
       "\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n",
       "\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n",
       "\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n",
       "\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
       "\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n",
       "\u001b[1;32m    230\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
       "\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n",
       "\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n",
       "\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n",
       "\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
       "\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
       "\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
       "\n",
       "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Output column label already exists."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)\nFile \u001b[0;32m<command-2902284467641502>:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringIndexer\n\u001b[1;32m      4\u001b[0m indexer \u001b[38;5;241m=\u001b[39m StringIndexer(inputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, outputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m indexer\u001b[38;5;241m.\u001b[39mfit(df)\u001b[38;5;241m.\u001b[39mtransform(df)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Show results to verify\u001b[39;00m\n\u001b[1;32m      8\u001b[0m df\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m10\u001b[39m)\n\nFile \u001b[0;32m/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_pyspark.py:30\u001b[0m, in \u001b[0;36m_create_patch_function.<locals>.patched_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m call_succeeded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     call_succeeded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/ml/wrapper.py:383\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[0;32m--> 383\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/ml/wrapper.py:380\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n\nFile \u001b[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\n\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Output column label already exists.",
       "errorSummary": "<span class='ansi-red-fg'>IllegalArgumentException</span>: requirement failed: Output column label already exists.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use StringIndexer to turn categorical string value into numeric indices\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"y\", outputCol=\"label\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "# Show results to verify\n",
    "df.select(\"y\", \"label\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "917f198d-8ede-4faf-85c7-df2ab10a8d22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "IdzCYnouEtlw"
   },
   "source": [
    "Window Functions (10 marks)\n",
    "* Use Spark SQL window functions to create at least one meaningful new feature from the existing data.  \n",
    "* In a markdown cell, clearly explain the logic and intended benefit of this new feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f36a144-5975-4308-84df-7b65f877fa48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8IbT2ctOEz-x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------------+\n",
      "|   job|balance|avg_balance_by_job|\n",
      "+------+-------+------------------+\n",
      "|admin.|    270| 1135.838909301876|\n",
      "|admin.|    390| 1135.838909301876|\n",
      "|admin.|     13| 1135.838909301876|\n",
      "|admin.|   -372| 1135.838909301876|\n",
      "|admin.|     39| 1135.838909301876|\n",
      "|admin.|    506| 1135.838909301876|\n",
      "|admin.|      0| 1135.838909301876|\n",
      "|admin.|   -171| 1135.838909301876|\n",
      "|admin.|    -76| 1135.838909301876|\n",
      "|admin.|      0| 1135.838909301876|\n",
      "+------+-------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Define window: group rows by job\n",
    "job_window = Window.partitionBy(\"job\")\n",
    "\n",
    "# Create the new column with average balance per job\n",
    "df = df.withColumn(\"avg_balance_by_job\", avg(\"balance\").over(job_window))\n",
    "\n",
    "# Show a few records\n",
    "df.select(\"job\", \"balance\", \"avg_balance_by_job\").show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7452da5-30c6-43d5-ba8e-fed028d62eda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "E9AYsjy1NASG"
   },
   "source": [
    "Feature: `avg_balance_by_job`\n",
    "\n",
    "This feature helps assess how a customer is doing financially compared to others in the same occupation. For example, if the average balance for admins is 1,135 but one admin only has 270, it suggests they may be financially underperforming relative to their peers, which could influence their financial decisions, such as whether to commit to a term deposit. While this feature is primarily useful for within-job comparison, it can also support indirect comparisons across jobs when used together with the encoded job feature. In doing so, the model can learn broader patterns. For instance, that some occupations generally have higher financial baselines than others, which may further refine its predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2657f88c-024d-42a6-af75-1ca201d244e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "HKON3RGWE0ek"
   },
   "source": [
    "#### Additional Features (7 marks)\n",
    "* Engineer at least two additional features based on customer demographics and campaign data.\n",
    "* Consider features that might capture customer behaviour or campaign\n",
    "characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f39561bc-9a81-4a13-a70c-b677e6748f47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|long_call_no_loan|count|\n",
      "+-----------------+-----+\n",
      "|                1| 5730|\n",
      "|                0|39481|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Create the new feature long_call_no_loan \n",
    "df = df.withColumn(\n",
    "    \"long_call_no_loan\",\n",
    "    when(\n",
    "        (col(\"duration\") > 260) & # since we know that the average call duration is 258.16, then 260 should be considered long\n",
    "        (col(\"housing\") == \"no\") &\n",
    "        (col(\"loan\") == \"no\"),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# Show a few records\n",
    "df.groupBy(\"long_call_no_loan\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d18114a-0c07-4525-9230-04e50b142fe8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+\n",
      "|age|balance|balance_to_age_ratio|\n",
      "+---+-------+--------------------+\n",
      "|58 |2143   |36.32203389830509   |\n",
      "|44 |29     |0.6444444444444445  |\n",
      "|33 |2      |0.058823529411764705|\n",
      "|47 |1506   |31.375              |\n",
      "|33 |1      |0.029411764705882353|\n",
      "|35 |231    |6.416666666666667   |\n",
      "|28 |447    |15.413793103448276  |\n",
      "|42 |2      |0.046511627906976744|\n",
      "|58 |121    |2.0508474576271185  |\n",
      "|43 |593    |13.477272727272727  |\n",
      "+---+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"balance_to_age_ratio\",\n",
    "    (col(\"balance\") / (col(\"age\") + 1))  # +1 to avoid division by 0\n",
    ")\n",
    "\n",
    "df.select(\"age\", \"balance\", \"balance_to_age_ratio\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0296b5b-673d-4918-b778-9707971125a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "985L5YpgE5w-"
   },
   "source": [
    "#### Documentation (3 marks)\n",
    "* In a markdown cell, justify your new features and explain how they could\n",
    "improve prediction performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8779c283-135a-4a63-aeb4-6695af777814",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Additional Feature 1: Long Call and No Loan (Binary)\n",
    "\n",
    "Based on our exploratory analysis in Task 1, we found that the average call duration was approximately 258 seconds. Therefore, we define \"long\" calls as those lasting more than 260 seconds, highlighting customers who were more engaged during the call.\n",
    "\n",
    "This feature captures customers who had a long call (**duration > 260 seconds**) and have **no housing or personal loans**. The assumption is that these individuals are both **financially unburdened** and **genuinely interested**, making them more likely to subscribe to a term deposit. This interaction feature combines **behavioral engagement** and **financial freedom** into a single binary indicator, helping the model identify high-potential customers more effectively.\n",
    "\n",
    "This feature captures customers who had a **long call** (**duration > 260 seconds**) and have **no housing or personal loans**. The assumption is that these individuals are both financially unburdened and genuinely interested, making them more likely to subscribe to a term deposit. It combines behavioral engagement with financial freedom into a single binary indicator.\n",
    "\n",
    "There are 5730 entries that fits this long call no loan criteria and 39481 that does not. This means approximately **12.7%** of the customers meet the criteria — a meaningful but not overwhelming subset of the data, ensuring the feature provides useful variation for model learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebf028ee-c788-49c8-8004-8f945af45d45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Additional Feature 2: balance to age ratio\n",
    "\n",
    "The `balance_to_age_ratio` feature captures a customer's financial standing relative to their age. While raw account balance provides a general sense of wealth, it lacks context. For example, a €2000 balance may represent financial strength for a 25-year-old but might be considered modest for someone nearing retirement. By normalizing balance over age, this feature helps the model better understand whether a customer is financially well-off for their life stage. Additionally, negative values reflect customers who are in debt, which can be a strong signal of low likelihood to subscribe to a term deposit. This feature adds interpretability and nuance to financial profiling in the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2dc900a-5f26-4f61-9f9d-9323dcbe98ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "JtnNZTyKD6pZ"
   },
   "source": [
    "### Task 3: Pipeline Construction and Model Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdbfee7e-cd0f-4ed6-a336-7cf50ce23825",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "gHCGSuN8FIoz"
   },
   "source": [
    "#### Pipeline Construction (12 marks)\n",
    "* Build a PySpark ML pipeline that includes:  \n",
    "1) Data transformations (including any applied via Spark SQL, if relevant).\n",
    "\n",
    "  2) A VectorAssembler to combine features.\n",
    "\n",
    "  3) A classifier (e.g. Logistic Regression) for predicting term deposit\n",
    "subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25c4efbe-12f5-46b7-8d15-4f54030470a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "6TcYgPqhD8nO"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, month, round as spark_round\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# 1. data transformation\n",
    "\n",
    "# all categorical features to be indexed and one-hot encoded\n",
    "categorical_features = [\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"poutcome\"]\n",
    "\n",
    "# StringIndexers \n",
    "indexers = [\n",
    "    StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"keep\")\n",
    "    for col in categorical_features\n",
    "]\n",
    "\n",
    "# OneHotEncoders\n",
    "encoders = [\n",
    "    OneHotEncoder(inputCol=col + \"_index\", outputCol=col + \"_vec\")\n",
    "    for col in categorical_features\n",
    "]\n",
    "\n",
    "# 2. vectorAssembler to combine all features into a single feature vector:\n",
    "\n",
    "# all numerical features \n",
    "numeric_features = [\n",
    "    \"age\", \"balance\", \"day\", \"duration\", \"campaign\", \"pdays\", \"previous\",\n",
    "    \"avg_balance_by_job\", \"balance_to_age_ratio\", \"long_call_no_loan\" # even though long_call_no_loan is categorical, it is already in binary \n",
    "]\n",
    "\n",
    "# Assemble all features into a single vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[col + \"_vec\" for col in categorical_features] + numeric_features,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# 3. Initialise the classifier (Logistic Regression)\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "\n",
    "# Construct the full pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, lr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4225b34-67b3-43f9-9924-9922275b1e18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ohR6uXZlFX8u"
   },
   "source": [
    "#### Hyperparameter Tuning (7 marks)\n",
    "* Implement cross-validation with a parameter grid (tune at least two\n",
    "hyperparameters).\n",
    "* Adjust the grid size and number of folds if necessary to work within the\n",
    "limitations of Community Edition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48aa4d12-a3c3-4dd2-8656-9755ef0f6b05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "dTGZODSsFiA0"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Split the data (80% train, 20% test)\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Set up a parameter grid for hyperparameter tuning\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0]) \\\n",
    "    .build()\n",
    "# regParam -> Strength of regularization (prevent overfitting), trying both weak (0.01) and strong (0.1) regularization\n",
    "# elasticNetParam -> L1 vs L2 regularization (Lasso vs Ridge), just try Ridge Regression (L2 regularization)\n",
    "\n",
    "# Define evaluator using area under the ROC curve\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "# help pick the best model\n",
    "\n",
    "# Set up CrossValidator with 3-fold cross-validation\n",
    "cv = CrossValidator(\n",
    "    estimator=pipeline,  # The entire ML pipeline\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3  # 3-fold cross-validation, reasonable for databricks CE\n",
    ")\n",
    "\n",
    "# Train the model using cross-validation\n",
    "cvModel = cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e607974d-04a4-4899-9df3-101d2bbbe38f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "cFe7b5nAFbOD"
   },
   "source": [
    "#### Documentation (6 marks)\n",
    "* In a markdown cell, describe the stages of your pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e552b627-6c6b-48b7-9f75-37e38d2c84b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "siC1YQUMV29P"
   },
   "source": [
    "The machine learning pipeline consists of the following stages:\n",
    "\n",
    "1. StringIndexers: Categorical features such as `job`, `marital`, `education`, and others are transformed into numerical indices using `StringIndexer`. This is necessary for compatibility with Spark ML models.\n",
    "\n",
    "2. OneHotEncoders: The indexed categorical features are further encoded into binary vectors using `OneHotEncoder`, allowing the model to treat them as distinct categories rather than ordinal numbers.\n",
    "\n",
    "3. **VectorAssembler**: All numerical features (including both original and engineered features like `avg_balance_by_job`, `balance_to_age_ratio`, and `long_call_no_loan`) and encoded categorical features are assembled into a single feature vector named `features`.\n",
    "\n",
    "4. **Logistic Regression**: A Logistic Regression model is used to classify whether a customer will subscribe to a term deposit (`label` = 1 for \"yes\", 0 for \"no\"). It supports regularization to prevent overfitting and works well for binary classification problems.\n",
    "\n",
    "5. **CrossValidator**: A 3-fold cross-validation is used to evaluate model performance across multiple parameter settings, allowing the best combination of hyperparameters to be selected based on Area Under ROC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fc667af-fd45-4a29-9809-41b0a39f2e49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "* In a markdown cell, explain how distributed processing in Spark benefits your ML\n",
    "pipeline and how hyperparameter tuning improves model performance,\n",
    "including any adjustments made due to resource constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf3bc5f8-c34e-440c-b63b-54696bfda9b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9q97sa87WQwR"
   },
   "source": [
    "Benefits of Distributed Processing in Spark: PySpark's MLlib runs transformations and model training across distributed workers. This allow for efficient handling of large datasets like `bank-full.csv`, faster feature transformation, model training, and evaluation using Spark clusters, and support for pipeline parallelism and lazy evaluation to minimize resource waste.\n",
    "\n",
    "Hyperparameter Tuning Justification: I used cross-validation to tune two parameters: `regParam` (regularization strength) and `elasticNetParam` (balance between L1 and L2 regularization). This improves generalizability and reduces overfitting. Due to Databricks Community Edition's limited resources, I used a smaller grid and 3-fold CV instead of 5 or 10 folds. This balances computation time with model quality, making it efficient yet effective for our environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d959dd0-53cc-4677-b410-eb9421ff5795",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "dxR8LffeD9HV"
   },
   "source": [
    "### Task 4: Model Evaluation and Innovation and Advanced Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48a06b36-46b8-448a-a641-60a3b1cc5b27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "-lz3mpaxFnfO"
   },
   "source": [
    "#### Model Evaluation (15 marks)\n",
    "* Split your data into training and test sets (80:20).\n",
    "* Evaluate your model on the test set using at least three metrics (e.g. accuracy,\n",
    "precision, recall, F1 score, or area under ROC).\n",
    "* Clearly display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bba389e4-0ff3-413c-a268-e46eb0b87562",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "mpRrSOy3EQTb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.9079\n",
      "Test Accuracy: 0.9026\n",
      "Test F1 Score: 0.8868\n",
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|0.0  |0.0       |[0.9290427370186412,0.07095726298135885]|\n",
      "|0.0  |0.0       |[0.9161813366000454,0.08381866339995458]|\n",
      "|1.0  |1.0       |[0.39529415882975855,0.6047058411702415]|\n",
      "|0.0  |0.0       |[0.8734226925101197,0.12657730748988028]|\n",
      "|1.0  |1.0       |[0.39236672113685717,0.6076332788631429]|\n",
      "|0.0  |0.0       |[0.6309218125032943,0.36907818749670573]|\n",
      "|1.0  |0.0       |[0.7180794911308055,0.2819205088691945] |\n",
      "|0.0  |0.0       |[0.8512903206231359,0.14870967937686408]|\n",
      "|0.0  |0.0       |[0.7386379230098638,0.26136207699013625]|\n",
      "|0.0  |0.0       |[0.9110928369439552,0.08890716305604485]|\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# Split dataset into training (80%) and test (20%)\n",
    "# already done it in task 3 before training the model and cross validation\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = cvModel.transform(test_df)\n",
    "\n",
    "# Evaluate model performance\n",
    "\n",
    "# AUC (Area Under ROC)\n",
    "auc_evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "auc = auc_evaluator.evaluate(predictions)\n",
    "print(f\"Test AUC: {auc:.4f}\")\n",
    "\n",
    "# Accuracy\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# F1 Score\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = f1_evaluator.evaluate(predictions)\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Show prediction samples\n",
    "predictions.select(\"label\", \"prediction\", \"probability\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa51f3ce-36f2-4f46-adc1-d489c4f213e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Test AUC: 0.9079\n",
    "\n",
    "Test Accuracy: 0.9026\n",
    "\n",
    "Test F1 Score: 0.8868\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4b9415a-9a4f-48ef-afae-19cf02b24e5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "zZ9o64SPFn_h"
   },
   "source": [
    "#### Innovation and Advanced Insights (10 marks)\n",
    "* In a markdown cell, propose an innovative or creative extension to your solution. This might include:  \n",
    "  1) Novel feature engineering techniques,\n",
    "  \n",
    "  2) Experimenting with an alternative machine learning algorithm,\n",
    "  \n",
    "  3) Creative visualisations of model performance or data distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68018620-9a5f-41d0-8469-9fabdb3aff87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Innovation: Experimenting with a Tree-Based Algorithm (Random Forest)\n",
    "\n",
    "While Logistic Regression is interpretable and efficient, it assumes linear relationships between features and the outcome. As an extension, I propose experimenting with a Random Forest Classifier, which is a tree-based ensemble method that can model non-linear interactions and complex feature relationships more effectively. Random Forests are also robust to outliers and can naturally handle categorical variables through feature splitting. Importantly, they provide feature importance scores, which offer insights into which variables are most influential in predicting term deposit subscriptions — a valuable asset for guiding business decisions. Given the relatively high class imbalance in the dataset, Random Forests can be further tuned using class weighting or sampling techniques to boost F1 score and recall. This extension could improve predictive performance and offer more nuanced interpretability beyond what Logistic Regression provides.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1439d81-9391-4a95-a968-f22c789fd095",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "* In a markdown cell, analyse your model's results. Discuss aspects like feature\n",
    "importance or model interpretability and explain how they add value to your\n",
    "assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44ce7c97-90c6-42b8-8b3a-00cc75721f42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The final model achieved strong performance on the test set:\n",
    "\n",
    "- **Accuracy**: 90.3%\n",
    "- **F1 Score**: 88.7%\n",
    "- **AUC**: 90.8%\n",
    "\n",
    "These results suggest the model is well-calibrated and generalizes well to unseen data. The high AUC reflects strong class separation, while the high F1 score indicates balanced precision and recall, which is crucial in a real-world marketing context where false positives and false negatives can be costly.\n",
    "\n",
    "Although Logistic Regression is less expressive than tree-based models, its transparency allows us to understand how each feature contributes to the outcome. Features like `duration`, `balance_to_age_ratio`, and `long_call_no_loan` likely played important roles by combining behavioral and financial indicators.\n",
    "\n",
    "In conclusion, this pipeline offers a practical and interpretable solution. With additional time or computational resources, further improvements could be achieved through model ensembling, richer visualizations, and more advanced feature extraction.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "BT4221_assignment2_submission",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
